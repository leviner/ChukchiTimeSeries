{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of operations\n",
    "\n",
    "1. Gadid specimen get in CLAMS2ABL based on genetic IDs provided by Sharon Wildes (ArcticEIS repo, specimenCorrections modelLen.py)\n",
    "2. Run MBA for 201701 and 201901\n",
    "3. Export the following tables:\n",
    "    - catchData\n",
    "        - mbaCatchResults (mbaCatchResults.sql)\n",
    "        - v_aeis_catch_summary_v2\n",
    "        - v_aeis_events\n",
    "        - v_aeis_specimen\n",
    "            - Build trawl selectivity tables:\n",
    "                - Add consistent lengths for all gadid specimen (Arctic EIS repo, specimenCorrections addCommonLength.py)\n",
    "                - Export Basket and sample tables from CLAMS2ABL:\n",
    "                    `select * from baskets where (ship = 175 and (survey = 201701 or survey = 201901)) or (ship = 174)`\n",
    "                    `select * from samples where (ship = 175 and (survey = 201701 or survey = 201901)) or (ship = 174)`\n",
    "                - Add expansion values to the table (Arctic EIS repo, trawlSelectivity buildSelectivityTable.ipynb)\n",
    "        - AIERP_EventData (ArcticEIS, EventExport.sql)\n",
    "            - Calculate volme filtered (aeisEvents EventData.ipynb)\n",
    "    - acousticData\n",
    "        - mbaIntegrationResults (mbaResultsExport.sql)\n",
    "        - mbaSpeciesProp (see SQL code below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap in 2019: 0.9222009870487491\n"
     ]
    }
   ],
   "source": [
    "abs(geod.geometry_area_perimeter(poly1.difference(poly2))[0])/abs(geod.geometry_area_perimeter(poly1)[0])\n",
    "print('overlap in 2019:',1-abs(geod.geometry_area_perimeter(poly1.difference(poly2))[0])/abs(geod.geometry_area_perimeter(poly2)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Geodesic area 2017: 148994.181 km^2\n",
      "overlap in 2017: 0.9195896511652564\n",
      "# Geodesic area 2019: 153995.194 km^2\n",
      "overlap in 2019: 0.9222009870487491\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Geod\n",
    "from shapely import wkt\n",
    "\n",
    "# specify a named ellipsoid\n",
    "# 2017\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "poly1 = wkt.loads('''\\\n",
    "POLYGON ((-168.60846216444355 66.99715863755357,-168.7086763789516 72.08417422880358,-165.9694878490645 72.08417422880358,-165.3682025620161 72.53302854567858,-157.41787487770966 72.57577657585715,-157.0170180196774 71.95593013826786,-157.65170804489514 70.97272544416072,\n",
    "-160.55792026562904 70.35287900657143,-163.93179882073386 69.946772719875,-164.13222724975 69.5192924180893,-166.40374944526613 68.49333969380356,-165.9026783727258 68.04448537692856,-164.46627463144355 67.55288302987499,-164.70010779862903 66.954410607375,-168.60846216444355 66.99715863755357))''')\n",
    "area = abs(geod.geometry_area_perimeter(poly1)[0])/1e+6\n",
    "print('# Geodesic area 2017: {:.3f} km^2'.format(area))\n",
    "print('overlap in 2017:',1-abs(geod.geometry_area_perimeter(poly1.difference(poly2))[0])/abs(geod.geometry_area_perimeter(poly1)[0]))\n",
    "\n",
    "poly2 = wkt.loads('''\\\n",
    "POLYGON ((-168.60107787551613 66.49453132622024,-168.60107787551613 72.5133516521131,-160.24014568166936 72.47401295717262,-159.32608878587902 72.98541599139881,-156.79899030928226 72.65103708440476,-157.12159862544354 71.76591644824404,-157.49797499429837 70.95947320196429,\n",
    "-163.95014131752419 70.192368650625,-164.08456144925805 69.5236108366369,-165.42876276659678 69.18923192964286,-166.93426824201612 68.81551432770833,-166.77296408393548 68.40245803083333,-165.75137108275806 68.12708716624999,-164.5684739235 67.22229718261904,-165.99332731987903 66.41585393633929,-168.60107787551613 66.49453132622024))''')\n",
    "area = abs(geod.geometry_area_perimeter(poly2)[0])/(1000*1000)\n",
    "print('# Geodesic area 2019: {:.3f} km^2'.format(area))\n",
    "print('overlap in 2019:',1-abs(geod.geometry_area_perimeter(poly1.difference(poly2))[0])/abs(geod.geometry_area_perimeter(poly2)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43439.71422095542"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "148994.181/(1/0.29155309240537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files...\n",
      "mean bottom depth:  46.015761131695015\n",
      "min bottom depth:  10.293944\n",
      "max bottom depth:  278.056195\n",
      "% shallower than  50  m:  76.05545053560176\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "def bottomDepths(files,refDepth):\n",
    "    print('reading files...')\n",
    "    hold = []\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        hold.append(df)\n",
    "    df = pd.concat(hold, axis=0, ignore_index=True)\n",
    "    bD = df.Exclude_below_line_depth_mean.values\n",
    "    bD[bD == -9999.0] = np.nan\n",
    "    bD = bD+0.5\n",
    "    print('mean bottom depth: ',np.nanmean(bD))\n",
    "    print('min bottom depth: ',np.nanmin(bD))\n",
    "    print('max bottom depth: ',np.nanmax(bD))\n",
    "    print('% shallower than ',refDepth,' m: ',(len(np.where(bD < refDepth)[0])/len(bD))*100)\n",
    "    plt.hist(bD, bins=100, density=True)\n",
    "    return df\n",
    "\n",
    "files17 = glob('../data/acousticData/2017_2019/EV/2017/Echoview/exports/5m/*(intervals).csv')\n",
    "files19 = glob('../data/acousticData/2017_2019/EV/2019/Echoview/exports/5m/*(intervals).csv')\n",
    "bD = bottomDepths(files17,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "files = glob('../data/acousticData/2017_2019/EV/2019/Echoview/exports/5m/*(intervals).csv')\n",
    "a = pd.concat(map(lambda file: pd.read_csv(file), files))\n",
    "a = a[(a.Lat_S < 999) & (a.Lon_S < 999)]\n",
    "plt.plot(a.Lon_S, a.Lat_S,'.')\n",
    "pts = plt.ginput(15)\n",
    "c = [str(b[0])+' '+str(b[1]) for b in pts]\n",
    "d = ','\n",
    "d.join(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 transit speed (m/s):  3.3434855897494025\n",
      "94412.59568999776\n",
      "2019 transit speed (m/s):  3.420634502352993\n",
      "118335.03655499949\n"
     ]
    }
   ],
   "source": [
    "# Transit speed\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "files = glob('../data/acousticData/2017_2019/EV/2017/Echoview/exports/5m/*(intervals).csv')\n",
    "a = pd.concat(map(lambda file: pd.read_csv(file), files))\n",
    "a['Datetime_S'] = pd.to_datetime(a['Date_S'].astype(str)+a['Time_S'])\n",
    "a['Datetime_E'] = pd.to_datetime(a['Date_E'].astype(str)+a['Time_E'])\n",
    "a['Duration'] = (a.Datetime_E- a.Datetime_S).dt.total_seconds()\n",
    "a['Dist'] = a['VL_end']-a['VL_start']\n",
    "a['Speed'] = a.Dist*1852/a.Duration\n",
    "print('2017 transit speed (m/s): ',a.Speed.mean())\n",
    "print(sum((a.Dist)*(30)))\n",
    "\n",
    "from glob import glob\n",
    "files = glob('../data/acousticData/2017_2019/EV/2019/Echoview/exports/5m/*(intervals).csv')\n",
    "a = pd.concat(map(lambda file: pd.read_csv(file), files))\n",
    "a['Datetime_S'] = pd.to_datetime(a['Date_S'].astype(str)+' '+a['Time_S'])\n",
    "a['Datetime_E'] = pd.to_datetime(a['Date_E'].astype(str)+' '+a['Time_E'])\n",
    "a['Duration'] = (a.Datetime_E- a.Datetime_S).dt.total_seconds()\n",
    "a['Dist'] = a['VL_end']-a['VL_start']\n",
    "a['Speed'] = a.Dist*1852/a.Duration\n",
    "print('2019 transit speed (m/s): ',a.Speed.mean())\n",
    "print(sum((a.Dist)*(45)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017, 38 @ .512:  25.117 -0.855\n",
      "2019, 38 @ .512:  25.16 -0.8\n",
      "0.02231264103257835\n",
      "2017, 38 @ 4.0:  25.32 -0.24\n",
      "2019, 38 @ 4.0:  25.367 -0.28\n",
      "0.0016105112976727565\n"
     ]
    }
   ],
   "source": [
    "# Calibration\n",
    "# From the E:\\ChukchiTimeSeries\\data\\acousticData\\2017_2019\\EV\\2019\\calibration\\Ocean Starr EK60 cals AFSC.xslx spreadhseet\n",
    "\n",
    "# 38 kHz 512\n",
    "# 2017 \n",
    "# Cal1: 25.23, -0.88\n",
    "# Cal2: 25.00, -0.83\n",
    "print('2017, 38 @ .512: ',round(10*np.log10(((10**(25.23/10))+(10**(25.00/10)))/2),3),round(10*np.log10(((10**(-.88/10))+(10**(-.83/10)))/2),3))\n",
    "\n",
    "# 2019\n",
    "# Cal1: 25.17, -0.84\n",
    "# Cal2: 25.15, -0.76\n",
    "print('2019, 38 @ .512: ',round(10*np.log10(((10**(25.17/10))+(10**(25.15/10)))/2),3),round(10*np.log10(((10**(-.84/10))+(10**(-.76/10)))/2),3))\n",
    "\n",
    "\n",
    "print(1-(10**((25.117-.855)/10))/(10**((25.16-.8)/10)))\n",
    "\n",
    "# 38 kHz 4\n",
    "# 2017 (only 1 cal) 25.32,-0.24\n",
    "print('2017, 38 @ 4.0: ',25.32,-0.24)\n",
    "\n",
    "# 2019\n",
    "# Cal1: 25.25, -0.28\n",
    "# Cal2: 25.48, -0.28\n",
    "print('2019, 38 @ 4.0: ',round(10*np.log10(((10**(25.25/10))+(10**(25.48/10)))/2),3),round(10*np.log10(((10**(-.28/10))+(10**(-.28/10)))/2),3))\n",
    "\n",
    "print(1-(10**((25.32 -0.24)/10))/(10**((25.367 -0.28)/10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017, 120 @ .512:  24.79 -0.46\n",
      "2019, 120 @ .512:  24.959 -0.45\n",
      "0.04037843288965892\n",
      "2017, 120 @ 1:  24.56 -0.39\n",
      "2019, 120 @ 1:  24.933 -0.355\n",
      "0.08966760032009014\n"
     ]
    }
   ],
   "source": [
    "# 120 kHz 512\n",
    "# 2017 \n",
    "# Cal1: 25.07, -0.41\n",
    "# Cal2: 24.49, -0.51\n",
    "print('2017, 120 @ .512: ',round(10*np.log10(((10**(25.07/10))+(10**(24.49/10)))/2),3),round(10*np.log10(((10**(-.41/10))+(10**(-.51/10)))/2),3))\n",
    "\n",
    "# 2019\n",
    "# Cal1: 25.39, -0.46\n",
    "# Cal2: 24.48, -0.44\n",
    "print('2019, 120 @ .512: ',round(10*np.log10(((10**(25.39/10))+(10**(24.48/10)))/2),3),round(10*np.log10(((10**(-.46/10))+(10**(-.44/10)))/2),3))\n",
    "\n",
    "print(1-(10**((24.79 -0.46)/10))/(10**((24.959 -0.45)/10)))\n",
    "\n",
    "# 120 kHz 1\n",
    "# 2017 (only 1 cal) 24.56, -0.39\n",
    "print('2017, 120 @ 1: ',24.56, -0.39)\n",
    "\n",
    "# 2019\n",
    "# Cal1: 25.36, -0.35\n",
    "# Cal2: 24.46, -0.36\n",
    "print('2019, 120 @ 1: ',round(10*np.log10(((10**(25.36/10))+(10**(24.46/10)))/2),3),round(10*np.log10(((10**(-.35/10))+(10**(-.36/10)))/2),3))\n",
    "\n",
    "print(1-(10**((24.56 -0.39)/10))/(10**((24.933 -0.355)/10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 vert opening +STD:  8.280166666666666 1.12605543084403\n",
      "2017 hori opening +STD:  7.559833333333334 0.9346034410133652\n",
      "2019 vert opening +STD:  7.533414634146343 0.5061650410493478\n",
      "2019 hori opening +STD:  7.449062499999999 0.3429413509060847\n",
      "2017 HR mean, min, max : 27.12212121212121 11.46 46.78\n",
      "2019 HR mean, min, max : 34.98837209302326 13.27 227.9\n"
     ]
    }
   ],
   "source": [
    "# Net Openings\n",
    "b = pd.read_csv('../data/catchData/2017_2019/AIERP_EventData.csv')\n",
    "print('2017 vert opening +STD: ',b[b.SURVEY==201701].AVG_NET_VERT_OPENING.mean(),b[b.SURVEY==201701].AVG_NET_VERT_OPENING.std())\n",
    "print('2017 hori opening +STD: ',b[b.SURVEY==201701].AVG_NET_HORI_OPENING.mean(),b[b.SURVEY==201701].AVG_NET_HORI_OPENING.std())\n",
    "print('2019 vert opening +STD: ',b[b.SURVEY==201901].AVG_NET_VERT_OPENING.mean(),b[b.SURVEY==201901].AVG_NET_VERT_OPENING.std())\n",
    "print('2019 hori opening +STD: ',b[b.SURVEY==201901].AVG_NET_HORI_OPENING.mean(),b[b.SURVEY==201901].AVG_NET_HORI_OPENING.std())\n",
    "print('2017 HR mean, min, max :',b[b.SURVEY==201701].AVG_HEAD_ROPE_DEPTH.mean(),b[b.SURVEY==201701].AVG_HEAD_ROPE_DEPTH.min(),b[b.SURVEY==201701].AVG_HEAD_ROPE_DEPTH.max())\n",
    "print('2019 HR mean, min, max :',b[b.SURVEY==201901].AVG_HEAD_ROPE_DEPTH.mean(),b[b.SURVEY==201901].AVG_HEAD_ROPE_DEPTH.min(),b[b.SURVEY==201901].AVG_HEAD_ROPE_DEPTH.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CTD per year:  68 55 39 46\n"
     ]
    }
   ],
   "source": [
    "# Number of CTD Stations\n",
    "c = pd.read_csv('catchAnalysis/analysisFiles/dfStat.csv')\n",
    "c = c[(~c.meanSa.isnull())&(~c.meanAcod.isnull())&(~c.meanPol.isnull())&(~c.meanCap.isnull())]\n",
    "print('# CTD per year: ',len(c[c.Year == 2012]),len(c[c.Year == 2013]),len(c[c.Year == 2017]),len(c[c.Year == 2019]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 All fishes  0.24789253188085802\n",
      "2017 All Arctic Cod  0.20975026751475034\n",
      "2019 All fishes  0.03478787966128983\n",
      "2019 All Arctic Cod  0.01788178450288881\n"
     ]
    }
   ],
   "source": [
    "# CPUE\n",
    "dfEvents = pd.read_csv('../data/catchData/2017_2019/AIERP_EventData.csv')\n",
    "catch = pd.read_csv('../data/catchData/2017_2019/catchExport.csv')\n",
    "events = pd.read_csv('../data/catchData/2017_2019/eventExport.csv')\n",
    "\n",
    "dfCatch = catch[(catch.GEAR == 'Marinovich') & (catch.SPECIES_CODE <40000) & (catch.SURVEY==201701)].merge(dfEvents, how='left',  left_on=['SURVEY','CLAMS_EVENT_NUMBER'],   right_on=['SURVEY','EVENT_ID'])\n",
    "dfCatch['CPUE'] = dfCatch.TOTAL_NUMBER_IN_HAUL/dfCatch.VOL_FILTERED\n",
    "dfCatch = dfCatch.groupby(by=['CLAMS_EVENT_NUMBER']).sum()\n",
    "print('2017 All fishes ',dfCatch.CPUE.mean())\n",
    "\n",
    "\n",
    "dfCatch = catch[(catch.GEAR == 'Marinovich') & (catch.SPECIES_CODE ==21725) & (catch.SURVEY==201701)].merge(dfEvents, how='left',  left_on=['SURVEY','CLAMS_EVENT_NUMBER'],   right_on=['SURVEY','EVENT_ID'])\n",
    "dfCatch['CPUE'] = dfCatch.TOTAL_NUMBER_IN_HAUL/dfCatch.VOL_FILTERED\n",
    "dfCatch = dfCatch.groupby(by=['CLAMS_EVENT_NUMBER']).sum()\n",
    "print('2017 All Arctic Cod ',dfCatch.CPUE.mean())\n",
    "\n",
    "dfCatch = catch[(catch.GEAR == 'Marinovich') & (catch.SPECIES_CODE <40000) & (catch.SURVEY==201901)].merge(dfEvents, how='left',  left_on=['SURVEY','CLAMS_EVENT_NUMBER'],   right_on=['SURVEY','EVENT_ID'])\n",
    "dfCatch['CPUE'] = dfCatch.TOTAL_NUMBER_IN_HAUL/dfCatch.VOL_FILTERED\n",
    "dfCatch = dfCatch.groupby(by=['CLAMS_EVENT_NUMBER']).sum()\n",
    "print('2019 All fishes ',dfCatch.CPUE.mean())\n",
    "\n",
    "\n",
    "dfCatch = catch[(catch.GEAR == 'Marinovich') & (catch.SPECIES_CODE ==21725) & (catch.SURVEY==201901)].merge(dfEvents, how='left',  left_on=['SURVEY','CLAMS_EVENT_NUMBER'],   right_on=['SURVEY','EVENT_ID'])\n",
    "dfCatch['CPUE'] = dfCatch.TOTAL_NUMBER_IN_HAUL/dfCatch.VOL_FILTERED\n",
    "dfCatch = dfCatch.groupby(by=['CLAMS_EVENT_NUMBER']).sum()\n",
    "print('2019 All Arctic Cod ',dfCatch.CPUE.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 length of 80 percentile:  7.3\n",
      "2019 length of 80 percentile:  8.0\n"
     ]
    }
   ],
   "source": [
    "# Lengths from catch\n",
    "a = pd.read_csv('../data/catchData/2017_2019/specimen_complete_selectivity.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "b = a[(a.SURVEY==201701)&(~a.CONSISTENT_LENGTH.isnull())].CONSISTENT_LENGTH.values\n",
    "print('2017 length of 80 percentile: ',np.percentile(b,80))\n",
    "b = a[(a.SURVEY==201901)&(~a.CONSISTENT_LENGTH.isnull())].CONSISTENT_LENGTH.values\n",
    "print('2019 length of 80 percentile: ',np.percentile(b,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "% fish abundance: 0.9522844828607858\n",
      "% Gad,cap,her abundance: 0.947263986489976\n",
      "% fish weight: 0.4480938138731442\n",
      "% jelly abundance: 0.02619677417103569\n",
      "% jelly weight: 0.5291975118480747\n",
      "C. melanaster:  0.9896329107693402\n",
      "2013\n",
      "% fish abundance: 0.8730348247786125\n",
      "% Gad,cap,her abundance: 0.8386735000776657\n",
      "% fish weight: 0.18414039341960067\n",
      "% jelly abundance: 0.03985783583825937\n",
      "% jelly weight: 0.7597752247689785\n",
      "C. melanaster:  0.9404935175553627\n"
     ]
    }
   ],
   "source": [
    "# Abundance and biomass from catch\n",
    "a = pd.read_csv('../data/catchData/2017_2019/catchExport.csv')\n",
    "a = a[((a.GEAR == 'Marinovich')|(a.GEAR == 'CanTrawl')) & (a.NET_PARTITION == 'Codend')]\n",
    "a = a[a.SURVEY == 2012001]\n",
    "a = a[(a.SPECIES_CODE >=1200)&(a.SPECIES_CODE < 60000)]\n",
    "aJel = np.unique(a[(a.SPECIES_CODE > 40000) & (a.SPECIES_CODE  < 50000)].SPECIES_CODE.values)# jellyfish\n",
    "aGad = np.unique( a[((a.SPECIES_CODE> 21700) & (a.SPECIES_CODE < 21750)) | (a.SPECIES_CODE == 1202)].SPECIES_CODE.values) # gadids    \n",
    "aSan =  np.unique(a[(a.SPECIES_CODE >= 20202) & (a.SPECIES_CODE <= 20204)].SPECIES_CODE.values) # sand lance\n",
    "aStic =  np.unique(a[(a.SPECIES_CODE >= 23800) & (a.SPECIES_CODE <= 23810)].SPECIES_CODE.values) # prickleback\n",
    "aCap =  np.unique(a[(a.SPECIES_CODE== 23041)].SPECIES_CODE.values) # capelin\n",
    "aHer =  np.unique(a[(a.SPECIES_CODE == 21110)].SPECIES_CODE.values) # herring\n",
    "print('2012')\n",
    "print('% fish abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% Gad,cap,her abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% fish weight:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('% jelly abundance:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% jelly weight:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('C. melanaster: ',a[a.SPECIES_CODE==40504].TOTAL_WEIGHT_IN_HAUL.sum()/a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "\n",
    "\n",
    "# Abundance and biomass from catch\n",
    "a = pd.read_csv('../data/catchData/2017_2019/catchExport.csv')\n",
    "a = a[((a.GEAR == 'Marinovich')|(a.GEAR == 'CanTrawl')) & (a.NET_PARTITION == 'Codend')]\n",
    "a = a[a.SURVEY == 2013001]\n",
    "a = a[(a.SPECIES_CODE >=1200)&(a.SPECIES_CODE < 60000)]\n",
    "aJel = np.unique(a[(a.SPECIES_CODE > 40000) & (a.SPECIES_CODE  < 50000)].SPECIES_CODE.values)# jellyfish\n",
    "aGad = np.unique( a[((a.SPECIES_CODE> 21700) & (a.SPECIES_CODE < 21750)) | (a.SPECIES_CODE == 1202)].SPECIES_CODE.values) # gadids    \n",
    "aSan =  np.unique(a[(a.SPECIES_CODE >= 20202) & (a.SPECIES_CODE <= 20204)].SPECIES_CODE.values) # sand lance\n",
    "aStic =  np.unique(a[(a.SPECIES_CODE >= 23800) & (a.SPECIES_CODE <= 23810)].SPECIES_CODE.values) # prickleback\n",
    "aCap =  np.unique(a[(a.SPECIES_CODE== 23041)].SPECIES_CODE.values) # capelin\n",
    "aHer =  np.unique(a[(a.SPECIES_CODE == 21110)].SPECIES_CODE.values) # herring\n",
    "print('2013')\n",
    "print('% fish abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% Gad,cap,her abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% fish weight:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('% jelly abundance:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% jelly weight:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('C. melanaster: ',a[a.SPECIES_CODE==40504].TOTAL_WEIGHT_IN_HAUL.sum()/a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHIP</th>\n",
       "      <th>SURVEY</th>\n",
       "      <th>CLAMS_EVENT_NUMBER</th>\n",
       "      <th>CLAMS_STATION_NUMBER</th>\n",
       "      <th>GRID_STATION_NAME</th>\n",
       "      <th>GEAR</th>\n",
       "      <th>NET_PARTITION</th>\n",
       "      <th>CATCH_SAMPLE_NUMBER</th>\n",
       "      <th>SPECIES_CODE</th>\n",
       "      <th>COMMON_NAME</th>\n",
       "      <th>SCIENTIFIC_NAME</th>\n",
       "      <th>SPECIES_SUBCATEGORY</th>\n",
       "      <th>TOTAL_WEIGHT_IN_HAUL</th>\n",
       "      <th>SAMPLED_WEIGHT</th>\n",
       "      <th>TOTAL_NUMBER_IN_HAUL</th>\n",
       "      <th>SAMPLED_NUMBER</th>\n",
       "      <th>FREQUENCY_EXPANSION</th>\n",
       "      <th>SAMPLED_IN_MIX</th>\n",
       "      <th>WHOLE_HAULED</th>\n",
       "      <th>COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>2012001</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CH-A01</td>\n",
       "      <td>CanTrawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>162</td>\n",
       "      <td>23041</td>\n",
       "      <td>Capelin</td>\n",
       "      <td>Mallotus villosus</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.084</td>\n",
       "      <td>148.5714</td>\n",
       "      <td>48</td>\n",
       "      <td>3.0952</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>2012001</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CH-A01</td>\n",
       "      <td>CanTrawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>166</td>\n",
       "      <td>40511</td>\n",
       "      <td>Aurelia sp.</td>\n",
       "      <td>Aurelia sp.</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174</td>\n",
       "      <td>2012001</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CH-A02</td>\n",
       "      <td>CanTrawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>168</td>\n",
       "      <td>21110</td>\n",
       "      <td>Pacific herring</td>\n",
       "      <td>Clupea pallasi</td>\n",
       "      <td>None</td>\n",
       "      <td>682.6600</td>\n",
       "      <td>13.260</td>\n",
       "      <td>7104.6063</td>\n",
       "      <td>138</td>\n",
       "      <td>51.4827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>2012001</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CH-A02</td>\n",
       "      <td>CanTrawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>169</td>\n",
       "      <td>23235</td>\n",
       "      <td>Chum salmon (juv)</td>\n",
       "      <td>Oncorhynchus keta</td>\n",
       "      <td>Immature</td>\n",
       "      <td>11.4600</td>\n",
       "      <td>11.460</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174</td>\n",
       "      <td>2012001</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CH-A02</td>\n",
       "      <td>CanTrawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>170</td>\n",
       "      <td>40504</td>\n",
       "      <td>Chrysaora melanaster</td>\n",
       "      <td>Chrysaora melanaster</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0400</td>\n",
       "      <td>2.160</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>175</td>\n",
       "      <td>201901</td>\n",
       "      <td>407</td>\n",
       "      <td>999.0</td>\n",
       "      <td>CH-B01</td>\n",
       "      <td>3m Beam Trawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>3403</td>\n",
       "      <td>72539</td>\n",
       "      <td>Margarites beringensis</td>\n",
       "      <td>Margarites beringensis</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.004</td>\n",
       "      <td>87.7820</td>\n",
       "      <td>14</td>\n",
       "      <td>6.2701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>175</td>\n",
       "      <td>201901</td>\n",
       "      <td>407</td>\n",
       "      <td>999.0</td>\n",
       "      <td>CH-B01</td>\n",
       "      <td>3m Beam Trawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>3404</td>\n",
       "      <td>72757</td>\n",
       "      <td>Buccinum ciliatum</td>\n",
       "      <td>Buccinum ciliatum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6.2701</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>175</td>\n",
       "      <td>201901</td>\n",
       "      <td>407</td>\n",
       "      <td>999.0</td>\n",
       "      <td>CH-B01</td>\n",
       "      <td>3m Beam Trawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>3405</td>\n",
       "      <td>1151</td>\n",
       "      <td>Boreotrophon truncatus</td>\n",
       "      <td>Boreotrophon truncatus</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.002</td>\n",
       "      <td>12.5403</td>\n",
       "      <td>2</td>\n",
       "      <td>6.2701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>175</td>\n",
       "      <td>201901</td>\n",
       "      <td>407</td>\n",
       "      <td>999.0</td>\n",
       "      <td>CH-B01</td>\n",
       "      <td>3m Beam Trawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>3406</td>\n",
       "      <td>71631</td>\n",
       "      <td>Tachyrhynchus sp.</td>\n",
       "      <td>Tachyrhynchus sp.</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.2701</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>175</td>\n",
       "      <td>201901</td>\n",
       "      <td>407</td>\n",
       "      <td>999.0</td>\n",
       "      <td>CH-B01</td>\n",
       "      <td>3m Beam Trawl</td>\n",
       "      <td>Codend</td>\n",
       "      <td>3407</td>\n",
       "      <td>72182</td>\n",
       "      <td>Obesotoma tenuilirata</td>\n",
       "      <td>Obesotoma tenuilirata</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12.5403</td>\n",
       "      <td>2</td>\n",
       "      <td>6.2701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6808 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SHIP   SURVEY  CLAMS_EVENT_NUMBER  CLAMS_STATION_NUMBER  \\\n",
       "0      174  2012001                   3                   1.0   \n",
       "1      174  2012001                   3                   1.0   \n",
       "2      174  2012001                   7                   3.0   \n",
       "3      174  2012001                   7                   3.0   \n",
       "4      174  2012001                   7                   3.0   \n",
       "...    ...      ...                 ...                   ...   \n",
       "6803   175   201901                 407                 999.0   \n",
       "6804   175   201901                 407                 999.0   \n",
       "6805   175   201901                 407                 999.0   \n",
       "6806   175   201901                 407                 999.0   \n",
       "6807   175   201901                 407                 999.0   \n",
       "\n",
       "     GRID_STATION_NAME           GEAR NET_PARTITION  CATCH_SAMPLE_NUMBER  \\\n",
       "0               CH-A01       CanTrawl        Codend                  162   \n",
       "1               CH-A01       CanTrawl        Codend                  166   \n",
       "2               CH-A02       CanTrawl        Codend                  168   \n",
       "3               CH-A02       CanTrawl        Codend                  169   \n",
       "4               CH-A02       CanTrawl        Codend                  170   \n",
       "...                ...            ...           ...                  ...   \n",
       "6803            CH-B01  3m Beam Trawl        Codend                 3403   \n",
       "6804            CH-B01  3m Beam Trawl        Codend                 3404   \n",
       "6805            CH-B01  3m Beam Trawl        Codend                 3405   \n",
       "6806            CH-B01  3m Beam Trawl        Codend                 3406   \n",
       "6807            CH-B01  3m Beam Trawl        Codend                 3407   \n",
       "\n",
       "      SPECIES_CODE             COMMON_NAME         SCIENTIFIC_NAME  \\\n",
       "0            23041                 Capelin       Mallotus villosus   \n",
       "1            40511             Aurelia sp.             Aurelia sp.   \n",
       "2            21110         Pacific herring          Clupea pallasi   \n",
       "3            23235       Chum salmon (juv)       Oncorhynchus keta   \n",
       "4            40504    Chrysaora melanaster    Chrysaora melanaster   \n",
       "...            ...                     ...                     ...   \n",
       "6803         72539  Margarites beringensis  Margarites beringensis   \n",
       "6804         72757       Buccinum ciliatum       Buccinum ciliatum   \n",
       "6805          1151  Boreotrophon truncatus  Boreotrophon truncatus   \n",
       "6806         71631       Tachyrhynchus sp.       Tachyrhynchus sp.   \n",
       "6807         72182   Obesotoma tenuilirata   Obesotoma tenuilirata   \n",
       "\n",
       "     SPECIES_SUBCATEGORY  TOTAL_WEIGHT_IN_HAUL  SAMPLED_WEIGHT  \\\n",
       "0                   None                0.2600           0.084   \n",
       "1                   None                0.0300           0.030   \n",
       "2                   None              682.6600          13.260   \n",
       "3               Immature               11.4600          11.460   \n",
       "4                   None                5.0400           2.160   \n",
       "...                  ...                   ...             ...   \n",
       "6803                None                0.0251           0.004   \n",
       "6804                None                0.0188           0.003   \n",
       "6805                None                0.0125           0.002   \n",
       "6806                None                0.0063           0.001   \n",
       "6807                None                0.0063           0.001   \n",
       "\n",
       "      TOTAL_NUMBER_IN_HAUL  SAMPLED_NUMBER  FREQUENCY_EXPANSION  \\\n",
       "0                 148.5714              48               3.0952   \n",
       "1                   0.0000               0               1.0000   \n",
       "2                7104.6063             138              51.4827   \n",
       "3                   4.0000               4               1.0000   \n",
       "4                   7.0000               3               2.3333   \n",
       "...                    ...             ...                  ...   \n",
       "6803               87.7820              14               6.2701   \n",
       "6804                6.2701               1               6.2701   \n",
       "6805               12.5403               2               6.2701   \n",
       "6806                6.2701               1               6.2701   \n",
       "6807               12.5403               2               6.2701   \n",
       "\n",
       "      SAMPLED_IN_MIX  WHOLE_HAULED COMMENTS  \n",
       "0                  0             1      NaN  \n",
       "1                  0             1      NaN  \n",
       "2                  0             1      NaN  \n",
       "3                  0             1      NaN  \n",
       "4                  0             1      NaN  \n",
       "...              ...           ...      ...  \n",
       "6803               1             0      NaN  \n",
       "6804               1             0      NaN  \n",
       "6805               1             0      NaN  \n",
       "6806               1             0      NaN  \n",
       "6807               1             0      NaN  \n",
       "\n",
       "[6808 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('../data/catchData/2017_2019/catchExport.csv')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "% fish abundance: 0.9863232129731636\n",
      "% Gad,cap,her abundance: 0.9627595542267834\n",
      "% fish weight: 0.16028538733154946\n",
      "% jelly abundance: 0.007698121572572092\n",
      "% jelly weight: 0.8383359547173879\n",
      "C. melanaster:  0.6088457142338402\n",
      "2019\n",
      "% fish abundance: 0.9342907275666883\n",
      "% Gad,cap,her abundance: 0.6369994922285663\n",
      "% fish weight: 0.06770644265539377\n",
      "% jelly abundance: 0.05539703561310407\n",
      "% jelly weight: 0.93123636563934\n",
      "C. melanaster:  0.5839014769756139\n"
     ]
    }
   ],
   "source": [
    "# Abundance and biomass from catch\n",
    "a = pd.read_csv('../data/catchData/2017_2019/catchExport.csv')\n",
    "a = a[(a.GEAR == 'Marinovich') & (a.NET_PARTITION == 'Codend')]\n",
    "a = a[a.SURVEY == 201701]\n",
    "a = a[(a.SPECIES_CODE >=1200)&(a.SPECIES_CODE < 60000)]\n",
    "aJel = np.unique(a[(a.SPECIES_CODE > 40000) & (a.SPECIES_CODE  < 50000)].SPECIES_CODE.values)# jellyfish\n",
    "aGad = np.unique( a[((a.SPECIES_CODE> 21700) & (a.SPECIES_CODE < 21750)) | (a.SPECIES_CODE == 1202)].SPECIES_CODE.values) # gadids    \n",
    "aSan =  np.unique(a[(a.SPECIES_CODE >= 20202) & (a.SPECIES_CODE <= 20204)].SPECIES_CODE.values) # sand lance\n",
    "aStic =  np.unique(a[(a.SPECIES_CODE >= 23800) & (a.SPECIES_CODE <= 23810)].SPECIES_CODE.values) # prickleback\n",
    "aCap =  np.unique(a[(a.SPECIES_CODE== 23041)].SPECIES_CODE.values) # capelin\n",
    "aHer =  np.unique(a[(a.SPECIES_CODE == 21110)].SPECIES_CODE.values) # herring\n",
    "print('2017')\n",
    "print('% fish abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% Gad,cap,her abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% fish weight:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('% jelly abundance:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% jelly weight:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('C. melanaster: ',a[a.SPECIES_CODE==40504].TOTAL_WEIGHT_IN_HAUL.sum()/a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "\n",
    "a = pd.read_csv('../data/catchData/2017_2019/catchExport.csv')\n",
    "a = a[(a.GEAR == 'Marinovich') & (a.NET_PARTITION == 'Codend')]\n",
    "a = a[a.SURVEY == 201901]\n",
    "a = a[(a.SPECIES_CODE >=1200)&(a.SPECIES_CODE < 60000)]\n",
    "aJel = np.unique(a[(a.SPECIES_CODE > 40000) & (a.SPECIES_CODE  < 50000)].SPECIES_CODE.values)# jellyfish\n",
    "aGad = np.unique( a[((a.SPECIES_CODE> 21700) & (a.SPECIES_CODE < 21750)) | (a.SPECIES_CODE == 1202)].SPECIES_CODE.values) # gadids    \n",
    "aSan =  np.unique(a[(a.SPECIES_CODE >= 20202) & (a.SPECIES_CODE <= 20204)].SPECIES_CODE.values) # sand lance\n",
    "aStic =  np.unique(a[(a.SPECIES_CODE >= 23800) & (a.SPECIES_CODE <= 23810)].SPECIES_CODE.values) # prickleback\n",
    "aCap =  np.unique(a[(a.SPECIES_CODE== 23041)].SPECIES_CODE.values) # capelin\n",
    "aHer =  np.unique(a[(a.SPECIES_CODE == 21110)].SPECIES_CODE.values) # herring\n",
    "print('2019')\n",
    "print('% fish abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% Gad,cap,her abundance:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aCap,aHer]))].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% fish weight:', a[a.SPECIES_CODE.isin(np.concatenate([aGad,aSan,aStic,aCap,aHer]))].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('% jelly abundance:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_NUMBER_IN_HAUL.sum()/a.TOTAL_NUMBER_IN_HAUL.sum())\n",
    "print('% jelly weight:', a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum()/a.TOTAL_WEIGHT_IN_HAUL.sum())\n",
    "print('C. melanaster: ',a[a.SPECIES_CODE==40504].TOTAL_WEIGHT_IN_HAUL.sum()/a[a.SPECIES_CODE.isin(aJel)].TOTAL_WEIGHT_IN_HAUL.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.90508847228669\n",
      "257.59256736688155\n",
      "1119.9412134358256\n",
      "178.53462277255952\n",
      "355.22825272607355\n",
      "2017 is X times higher than the other years:  15.556328233657856 4.343689320388349 6.266106442577031 3.152480270574972\n"
     ]
    }
   ],
   "source": [
    "# Backscatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df2012Summary = pd.read_csv('../data/acousticData/2012_2013/Arctic_EIS_Acoustic_trawl_survey_alongtrack_summary_2012_v3.csv')\n",
    "df2013Summary = pd.read_csv('../data/acousticData/2012_2013/Arctic_EIS_Acoustic_trawl_survey_alongtrack_summary_2013_v3.csv')\n",
    "df2017Summary = pd.read_csv('../data/acousticData/2017_2019/Arctic_EIS_Acoustic_trawl_survey_alongtrack_summary_2017.csv')\n",
    "df2018Summary = pd.read_csv('../data/acousticData/2018/Arctic_EIS_Acoustic_trawl_survey_alongtrack_summary_2018.csv')\n",
    "df2019Summary = pd.read_csv('../data/acousticData/2017_2019/Arctic_EIS_Acoustic_trawl_survey_alongtrack_summary_2019.csv')\n",
    "print(np.mean(df2012Summary['Fish 38 kHz sA (m^2 nmi^-2)'][(df2012Summary.Latitude > 66) & (df2012Summary.Longitude < -156.7)]))# & (df2012Summary.Latitude  < 71.85)]))\n",
    "print(np.mean(df2013Summary['Fish 38 kHz sA (m^2 nmi^-2)'][(df2013Summary.Latitude > 66)& (df2013Summary.Longitude < -156.7)]))# & (df2013Summary.Latitude  < 71.85)]))\n",
    "print(np.mean(df2017Summary['Fish 38 kHz sA (m^2 nmi^-2)'][(df2017Summary.Latitude > 66)& (df2017Summary.Longitude < -156.7)]))# & (df2017Summary.Latitude  < 71.85)]))\n",
    "print(np.mean(df2018Summary['Fish 38 kHz sA (m^2 nmi^-2)'][(df2018Summary.Latitude > 66)]))# & (df2018Summary.Latitude  < 71.85)]))\n",
    "print(np.mean(df2019Summary['Fish 38 kHz sA (m^2 nmi^-2)'][(df2019Summary.Latitude > 66)& (df2019Summary.Longitude < -156.7)]))# & (df2019Summary.Latitude  < 71.85)]))\n",
    "print('2017 is X times higher than the other years: ',1118.5/71.9,1118.5/257.5,1118.5/178.5,1118.5/354.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pollock 2017: 72267247847.093\n",
      "Pollock 2019: 57401559641.71512\n",
      "Acod 2017: 877391394396.3812\n",
      "Acod 2019: 125555744574.5253\n",
      "Capelin 2017: 15846782605.369555\n",
      "Capelin 2019: 3738074434.0081444\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('../data/catchData/2017_2019/mbaCatchResults.csv')\n",
    "a.SPECIES_CODE.unique()\n",
    "#pollock\n",
    "print('Pollock 2017:',a[(a.SURVEY==201701)&(a.SPECIES_CODE==21744)&(a.END_LONGITUDE <-156.7)].NUMBERS.sum())\n",
    "print('Pollock 2019:',a[(a.SURVEY==201901)&(a.SPECIES_CODE==21744)&(a.END_LONGITUDE <-156.7)].NUMBERS.sum())\n",
    "#arctic cod\n",
    "print('Acod 2017:',a[(a.SURVEY==201701)&(a.SPECIES_CODE==21725)&(a.END_LONGITUDE <-156.7)].NUMBERS.sum())\n",
    "print('Acod 2019:',a[(a.SURVEY==201901)&(a.SPECIES_CODE==21725)&(a.END_LONGITUDE <-156.7)].NUMBERS.sum())\n",
    "# capelin\n",
    "print('Capelin 2017:',a[(a.SURVEY==201701)&(a.SPECIES_CODE==23041)&(a.END_LONGITUDE <-156.7)].NUMBERS.sum())\n",
    "print('Capelin 2019:',a[(a.SURVEY==201901)&(a.SPECIES_CODE==23041)&(a.END_LONGITUDE <-156.7)].NUMBERS.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 Gadids: 0.9838883646443122\n",
      "2019 Gadids: 0.9641131437639759\n",
      "2017 Arctic cod: 0.8953858684823652\n",
      "2019 Arctic cod: 0.6516882495320803\n",
      "2017 Pollock: 0.0745312279899934\n",
      "2019 Pollock: 0.29801677432207296\n"
     ]
    }
   ],
   "source": [
    "specs = [21725, 21744, 21740, 21735, 21720]\n",
    "print('2017 Gadids:',a[(a.SURVEY==201701)&(a.SPECIES_CODE.isin(specs))].NUMBERS.sum()/a[(a.SURVEY==201701)].NUMBERS.sum())\n",
    "print('2019 Gadids:',a[(a.SURVEY==201901)&(a.SPECIES_CODE.isin(specs))].NUMBERS.sum()/a[(a.SURVEY==201901)].NUMBERS.sum())\n",
    "\n",
    "print('2017 Arctic cod:',a[(a.SURVEY==201701)&(a.SPECIES_CODE==21725)].NUMBERS.sum()/a[(a.SURVEY==201701)].NUMBERS.sum())\n",
    "print('2019 Arctic cod:',a[(a.SURVEY==201901)&(a.SPECIES_CODE==21725)].NUMBERS.sum()/a[(a.SURVEY==201901)].NUMBERS.sum())\n",
    "\n",
    "print('2017 Pollock:',a[(a.SURVEY==201701)&(a.SPECIES_CODE.isin([21740,21744]))].NUMBERS.sum()/a[(a.SURVEY==201701)].NUMBERS.sum())\n",
    "print('2019 Pollock:',a[(a.SURVEY==201901)&(a.SPECIES_CODE.isin([21740,21744]))].NUMBERS.sum()/a[(a.SURVEY==201901)].NUMBERS.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201701 23041 1.5846782605369554\n",
      "201701 21744 7.2267247847093\n",
      "201701 21725 87.73913943963812\n",
      "201701 21720 0.9412550247454395\n",
      "201701 21735 0.46004876872346534\n",
      "201701 21110 0.0\n",
      "201701 21740 0.0\n",
      "201901 23041 0.37380744340081445\n",
      "201901 21744 5.740155964171512\n",
      "201901 21725 12.55557445745253\n",
      "201901 21720 0.08921857967994705\n",
      "201901 21735 0.18837154481527138\n",
      "201901 21110 0.31742012372610956\n",
      "201901 21740 0.0012176257066017209\n"
     ]
    }
   ],
   "source": [
    "#Abundances by survey by species\n",
    "for surv in a.SURVEY.unique():\n",
    "    for spec in a.SPECIES_CODE.unique():\n",
    "        print(surv,spec,a[(a.SURVEY==surv)&(a.SPECIES_CODE==spec)&(a.END_LONGITUDE <-156.7)].NUMBERS.sum()/10**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012 Acod: 3.5271698674469336\n",
      "2013 Acod: 3.55174105365163\n",
      "2017 Acod: 4.408042066718216\n",
      "2019 Acod: 4.808930212883881\n",
      "2012 pollock: 4.971642230484027\n",
      "2013 pollock: 6.828973597980371\n",
      "2017 pollock: 5.107030595963149\n",
      "2019 pollock: 5.068405358275401\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# lengths of arctic cod and pollock\n",
    "df2012 = pd.read_csv('../data/catchData/2012_2013/Arctic_EIS_AT_survey_Arctic_cod_by_length_alongtrack_fish_per_m_squared_2012_v3.csv')\n",
    "df2013 = pd.read_csv('../data/catchData/2012_2013/Arctic_EIS_AT_survey_Arctic_cod_by_length_alongtrack_fish_per_m_squared_2013_v3.csv')\n",
    "df2017 = pd.read_csv('../data/catchData/2017_2019/Arctic_EIS_201701_21725.csv')\n",
    "df2019 = pd.read_csv('../data/catchData/2017_2019/Arctic_EIS_201901_21725.csv')\n",
    "print('2012 Acod:',sum(df2012[df2012.Latitude >=65.9].sum()[3:]/sum(df2012[df2012.Latitude >=65.9].sum()[3:])*np.arange(2,31,1)))\n",
    "print('2013 Acod:',sum(df2013[df2013.Latitude >=65.9].sum()[3:]/sum(df2013[df2013.Latitude >=65.9].sum()[3:])*np.arange(2,31,1)))\n",
    "print('2017 Acod:',sum(df2017.sum()[3:23]/sum(df2017.sum()[3:23])*np.arange(1,19,1)))\n",
    "print('2019 Acod:',sum(df2019.sum()[3:23]/sum(df2019.sum()[3:23])*np.arange(1,21,1)))\n",
    "\n",
    "#pollock\n",
    "df2012 = pd.read_csv('../data/catchData/2012_2013/Arctic_EIS_AT_survey_pollock_by_length_alongtrack_fish_per_m_squared_2012_v3.csv')\n",
    "df2013 = pd.read_csv('../data/catchData/2012_2013/Arctic_EIS_AT_survey_pollock_by_length_alongtrack_fish_per_m_squared_2013_v3.csv')\n",
    "df2017 = pd.read_csv('../data/catchData/2017_2019/Arctic_EIS_201701_21744.csv')\n",
    "df2019 = pd.read_csv('../data/catchData/2017_2019/Arctic_EIS_201901_21744.csv')\n",
    "print('2012 pollock:',sum(df2012.sum()[3:23]/sum(df2012.sum()[3:23])*np.arange(2,22,1)))\n",
    "print('2013 pollock:',sum(df2013.sum()[3:23]/sum(df2013.sum()[3:23])*np.arange(2,22,1)))\n",
    "print('2017 pollock:',sum(df2017.sum()[3:23]/sum(df2017.sum()[3:23])*np.arange(1,19,1)))\n",
    "print('2019 pollock:',sum(df2019.sum()[3:23]/sum(df2019.sum()[3:23])*np.arange(1,21,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of acoustic backscatter attributed to the key species\n",
    "```sql\n",
    "select a.survey, b.event_id,a.interval,  a.layer,a.prc_nasc, c.species_code, c.sa_proportion\n",
    "from \n",
    "(select * from integration_results) a\n",
    "join\n",
    "(select * from v_mean_sigma_by_interval_class) b\n",
    "on a.interval = b.interval\n",
    "and a.ship = b.ship\n",
    "and a.survey = b.survey\n",
    "join\n",
    "(select * from scaling_key_sa_by_species) c\n",
    "on b.event_id = c.event_id\n",
    "and b.ship = c.ship\n",
    "and b.survey = c.survey\n",
    "where a.ship = 175 and (a.survey=201701 or a.survey = 201901)\n",
    "order by a.interval, c.species_code\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPECIES_CODE</th>\n",
       "      <th>NASC_SPECIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21725</td>\n",
       "      <td>2.121468e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21744</td>\n",
       "      <td>9.728182e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21735</td>\n",
       "      <td>2.225326e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21720</td>\n",
       "      <td>1.515828e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23041</td>\n",
       "      <td>8.660144e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>23808</td>\n",
       "      <td>8.464975e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23801</td>\n",
       "      <td>2.520251e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21334</td>\n",
       "      <td>9.884667e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21368</td>\n",
       "      <td>5.670676e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23800</td>\n",
       "      <td>5.363116e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SPECIES_CODE  NASC_SPECIES\n",
       "14         21725  2.121468e+06\n",
       "16         21744  9.728182e+05\n",
       "15         21735  2.225326e+05\n",
       "13         21720  1.515828e+05\n",
       "19         23041  8.660144e+04\n",
       "25         23808  8.464975e+04\n",
       "21         23801  2.520251e+04\n",
       "8          21334  9.884667e+03\n",
       "9          21368  5.670676e+03\n",
       "20         23800  5.363116e+03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop key spec:  0.959912798031704\n",
      "Prop gadid:  0.9365288980256332\n",
      "Prop jelly:  0.002005038156850882\n",
      "2019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPECIES_CODE</th>\n",
       "      <th>NASC_SPECIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21744</td>\n",
       "      <td>1.860306e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21725</td>\n",
       "      <td>8.055948e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21735</td>\n",
       "      <td>2.968549e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21110</td>\n",
       "      <td>1.710237e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>23807</td>\n",
       "      <td>1.026548e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23041</td>\n",
       "      <td>8.184877e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21720</td>\n",
       "      <td>5.376915e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>23800</td>\n",
       "      <td>3.123052e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21740</td>\n",
       "      <td>3.100961e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>40504</td>\n",
       "      <td>2.907665e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SPECIES_CODE  NASC_SPECIES\n",
       "21         21744  1.860306e+06\n",
       "18         21725  8.055948e+05\n",
       "19         21735  2.968549e+05\n",
       "9          21110  1.710237e+05\n",
       "31         23807  1.026548e+05\n",
       "27         23041  8.184877e+04\n",
       "17         21720  5.376915e+04\n",
       "29         23800  3.123052e+04\n",
       "20         21740  3.100961e+04\n",
       "33         40504  2.907665e+04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop key spec:  0.927883722923627\n",
      "Prop gadid:  0.8567905930082398\n",
      "Prop jelly:  0.012760012995581032\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('../data/acousticData/2017_2019/mbaSpeciesProp.csv')\n",
    "a['NASC_SPECIES'] = a.PRC_NASC*a.SA_PROPORTION\n",
    "\n",
    "c = a[a.SURVEY==201701]\n",
    "b = c.groupby(by=['SPECIES_CODE']).sum().reset_index()\n",
    "print('2017')\n",
    "display(b.sort_values(by='NASC_SPECIES',ascending=False)[['SPECIES_CODE','NASC_SPECIES']].head(10))\n",
    "specs = [21110, 23041, 21725, 21744, 21740, 21735, 21720]\n",
    "b[b.SPECIES_CODE.isin(specs)].NASC_SPECIES.sum()/b.NASC_SPECIES.sum()\n",
    "print('Prop key spec: ',b[b.SPECIES_CODE.isin(specs)].NASC_SPECIES.sum()/b.NASC_SPECIES.sum())\n",
    "specs = [21725, 21744, 21740, 21735, 21720]\n",
    "print('Prop gadid: ',b[b.SPECIES_CODE.isin(specs)].NASC_SPECIES.sum()/b.NASC_SPECIES.sum())\n",
    "print('Prop jelly: ',b[(b.SPECIES_CODE>40000)&(b.SPECIES_CODE<50000)].NASC_SPECIES.sum()/b.NASC_SPECIES.sum())\n",
    "\n",
    "c = a[a.SURVEY==201901]\n",
    "print('2019')\n",
    "b = c.groupby(by=['SPECIES_CODE']).sum().reset_index()\n",
    "display(b.sort_values(by='NASC_SPECIES',ascending=False)[['SPECIES_CODE','NASC_SPECIES']].head(10))\n",
    "specs = [21110, 23041, 21725, 21744, 21740, 21735, 21720]\n",
    "print('Prop key spec: ',b[b.SPECIES_CODE.isin(specs)].NASC_SPECIES.sum()/b.NASC_SPECIES.sum())\n",
    "specs = [21725, 21744, 21740, 21735, 21720]\n",
    "print('Prop gadid: ',b[b.SPECIES_CODE.isin(specs)].NASC_SPECIES.sum()/b.NASC_SPECIES.sum())\n",
    "print('Prop jelly: ',b[(b.SPECIES_CODE>40000)&(b.SPECIES_CODE<50000)].NASC_SPECIES.sum()/b.NASC_SPECIES.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of pollock found in catch north of the strait in 2012 and 2013 in the catch\n",
    "```sql \n",
    "select b.eq_latitude, a.*\n",
    "from\n",
    "(select * from v_aeis_catch_summary_v2 where survey=2012001 and (species_code = 21740 or species_code = 21744)) a\n",
    "join\n",
    "(select * from v_event_data) b\n",
    "on a.ship = b.ship and a.survey = b.survey and a.clams_event_number = b.event_id\n",
    "order by eq_latitude\n",
    "```\n",
    "\n",
    "28 in 2012, 2 in 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStat = pd.read_csv('catchAnalysis/analysisFiles/dfStat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.577283333333334 -0.7174166666666667\n",
      "34.73803333333333 31.094583333333336\n"
     ]
    }
   ],
   "source": [
    "#dfStat[dfStat.Year == 2017].T_surf.mean()\n",
    "print(dfStat[dfStat.Year == 2017].T_bot.max(),dfStat[dfStat.Year == 2017].T_bot.min())\n",
    "print(dfStat[dfStat.Year == 2017].S_bot.max(),dfStat[dfStat.Year == 2017].S_bot.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 genetics done:  755\n",
      "2017 all specimen:  2244\n",
      "2019 genetics done:  2983\n",
      "2019 all specimen:  5654\n"
     ]
    }
   ],
   "source": [
    "# This is not up to date...\n",
    "a = pd.read_csv('C:/Users/robert.levine/Work/repositories/ArcticEISII/catchProcessing/code/specimenCorrections/geneticID/data/gadidsUpdatedLen.csv')\n",
    "a = a[(a.GEAR=='Marinovich')&(a.PARTITION=='Codend')]\n",
    "print('2017 genetics done: ',len(a[(a.SURVEY==201701) & ((a.SPECIES_ID_METHOD=='genetics_changed')|(a.SPECIES_ID_METHOD=='genetics_confirmed'))]))\n",
    "print('2017 all specimen: ',len(a[(a.SURVEY==201701)]))\n",
    "\n",
    "print('2019 genetics done: ',len(a[(a.SURVEY==201901) & ((a.SPECIES_ID_METHOD=='genetics_changed')|(a.SPECIES_ID_METHOD=='genetics_confirmed'))]))\n",
    "print('2019 all specimen: ',len(a[(a.SURVEY==201901)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql select count(*) from v_aeis_specimen\n",
    "where survey = 201701 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and species_code < 40000\n",
    "\n",
    "3392\n",
    "\n",
    "and species_code > 40000\n",
    "\n",
    "1211\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201701 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and (species_code > 21700\n",
    "and species_code < 21800\n",
    "or species_code = 1202)\n",
    "order by species_code\n",
    "\n",
    "2244\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201701 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and (species_id_method = 'genetics_confirmed'\n",
    "or species_id_method = 'genetics_changed')\n",
    "\n",
    "894\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201701 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and species_id_method = 'genetics_model_assigned'\n",
    "\n",
    "1350\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201701 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and species_id_method = 'field_id'\n",
    "\n",
    "0\n",
    "\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201901 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and species_code < 40000\n",
    "\n",
    "9124\n",
    "\n",
    "and species_code > 40000\n",
    "\n",
    "751\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201901 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and (species_code > 21700\n",
    "and species_code < 21800\n",
    "or species_code = 1202)\n",
    "order by species_code\n",
    "\n",
    "5676\n",
    "\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201901 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and (species_id_method = 'genetics_confirmed'\n",
    "or species_id_method = 'genetics_changed')\n",
    "\n",
    "3155\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201901 and\n",
    "gear = 'Marinovich'\n",
    "and species_id_method = 'genetics_model_assigned'\n",
    "\n",
    "2488\n",
    "\n",
    "select count(*) from v_aeis_specimen\n",
    "where survey = 201901 and\n",
    "gear = 'Marinovich'\n",
    "and net_partition = 'Codend'\n",
    "and species_id_method = 'field_id'\n",
    "\n",
    "11\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
